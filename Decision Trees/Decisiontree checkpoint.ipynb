{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import seaborn as sb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"titanic-passengers.csv\", sep=\";\")\n",
    "new_data = pd.DataFrame.copy(data)\n",
    "\n",
    "# Displaying the first five rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concise summary of a DataFrame.\n",
    "data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing descriptive statistics\n",
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing survived and Sex columns from categorical to numerical\n",
    "# for survived: yes = 1, no = 0\n",
    "# for Sex: male = 1, female = 0\n",
    "new_data[\"Survived\"] = new_data[\"Survived\"].map({\"Yes\":1, \"No\":0})\n",
    "new_data[\"Sex\"] = new_data[\"Sex\"].map({\"male\":1, \"female\":0})\n",
    "\n",
    "# One-hot-Encoding the Embarked column\n",
    "new_data = pd.get_dummies(new_data, columns=[\"Embarked\"])\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding correlations between features and outcome\n",
    "def dataCorr(data):\n",
    "    data_corr = data.corr()\n",
    "    mask = np.zeros_like(data_corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    mp.pyplot.subplots(figsize=(15, 15))\n",
    "    dataplot = sb.heatmap(data_corr, annot=True, cmap=\"coolwarm\", mask=mask, center=0, square=True, fmt=\".2f\")\n",
    "    mp.pyplot.xticks(rotation = 45)\n",
    "    mp.pyplot.show()\n",
    "    \n",
    "dataCorr(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding missing values\n",
    "new_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed columns that I found to be useless\n",
    "new_data.drop(columns=[\"Cabin\", \"Ticket\"], inplace=True)\n",
    "\n",
    "# Filling in the missing cabins\n",
    "# new_data[\"Cabin\"] = new_data[\"Cabin\"].fillna(\"G6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding missing values\n",
    "new_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1- Data Cleaning\n",
    "##### Finding outliers:\n",
    "- Finding the rows that are considered outliers and removing them from the dataset we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def detectOutliers(data, n, features):\n",
    "    outlier_rows = []\n",
    "    for col in features:\n",
    "        Q1 = np.percentile(data[col], 25)\n",
    "        Q3 = np.percentile(data[col], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlierStep = IQR * 1.5\n",
    "        outlierList = data[(data[col] < Q1 - outlierStep ) | (data[col] > Q3 + outlierStep)].index\n",
    "        outlier_rows.extend(outlierList)\n",
    "    # Counts the frequency of occurrences of each row index\n",
    "    outlier_rows = Counter(outlier_rows)\n",
    "    multiple_outliers = list(key for key, value in outlier_rows.items() if value > n)\n",
    "    return multiple_outliers\n",
    "\n",
    "outliers_to_drop = detectOutliers(new_data, 2, [\"Age\", \"SibSp\", \"Fare\", \"Parch\"])\n",
    "print(\"these rows will be dropped due to their outlier values: {} \".format(outliers_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before removing the outliers we have {} rows\".format(len(new_data)))\n",
    "new_data = new_data.drop(outliers_to_drop, axis=0).reset_index(drop=True)\n",
    "print(\"After removing the outliers we have {} rows\".format(len(new_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Visualisation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\"Sex\", \"Fare\", \"Pclass\", \"Embarked_C\", \"Embarked_Q\", \"Embarked_S\"]\n",
    "\n",
    "mp.pyplot.subplots(figsize=(10, 10))\n",
    "mp.pyplot.subplot(2, 2, 1)\n",
    "sb.histplot(data = data, x = \"Sex\", hue = \"Survived\", multiple=\"dodge\")\n",
    "mp.pyplot.subplot(2, 2, 2)\n",
    "sb.histplot(data = data, x = \"Fare\", hue = \"Survived\", multiple=\"dodge\", bins = 7)\n",
    "mp.pyplot.subplot(2, 2, 3)\n",
    "sb.histplot(data = data, x = \"Pclass\", hue = \"Survived\", multiple=\"dodge\")\n",
    "mp.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sb.FacetGrid(data, col=\"Sex\", row=\"Survived\")\n",
    "grid.map(sb.histplot, \"Age\")\n",
    "\n",
    "grid = sb.FacetGrid(data, col=\"Pclass\", row=\"Survived\", legend_out=True)\n",
    "grid.map(sb.histplot, \"Fare\", kde = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sb.histplot(data = new_data,x=\"Fare\", kde=True, stat=\"density\", label=(\"Skewness: {}\".format(round(new_data[\"Fare\"].skew(), 2))))\n",
    "g.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2- Observation\n",
    "##### from the FacetGrids and Histoplots:\n",
    "- The Fare is positively skewed making alot of the points seem like an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the skewness of the fare values\n",
    "new_data[\"Fare\"] = new_data[\"Fare\"].map(lambda x: np.log(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sb.histplot(data = new_data,x=\"Fare\", kde=True, stat=\"density\", label=(\"Skewness: {}\".format(round(new_data[\"Fare\"].skew(), 2))))\n",
    "g.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2- Observation\n",
    "##### from the FacetGrids:\n",
    "- The lower the fare, the more likely the person was on a lower Pclass\n",
    "  - More people survived than died from Pclass 1\n",
    "  - the survived to died ratio were very close to the ones in Pclass 2\n",
    "  - Pclass 3 had the most casualties\n",
    "- Most passengers were between the age 20 and 40\n",
    "  - More Males died than Females\n",
    "  - More Females survived than Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCorr(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingAge = list(new_data[new_data[\"Age\"].isnull()].index)\n",
    "len(missingAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sb.catplot(data=new_data, x=\"Sex\", y=\"Age\", hue=\"Pclass\", kind=\"box\", col=\"Survived\")\n",
    "g = sb.catplot(data=new_data, x=\"Parch\", y=\"Age\", kind=\"box\", col=\"Survived\")\n",
    "g = sb.catplot(data=new_data, x=\"SibSp\", y=\"Age\", kind=\"box\", col=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCorr(new_data[[\"Age\", \"SibSp\", \"Parch\", \"Sex\", \"Fare\", \"Pclass\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3- Observation\n",
    "##### from the correlation graph:\n",
    "- We can see that Age is in correlated with sex or Fare much\n",
    "- Age is correlated with Pclass, Parch, and SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in the missing age values with the median of values that have the same Sibsp, Parch and Pclass values\n",
    "# or filling it with the median of all the values combined\n",
    "\n",
    "for i in missingAge:\n",
    "    medianAge = new_data[\"Age\"].dropna().median()\n",
    "    AssumedAge = new_data[\"Age\"][(new_data[\"SibSp\"] == new_data.iloc[i][\"SibSp\"])\n",
    "                                 & (new_data[\"Parch\"] == new_data.iloc[i][\"Parch\"])\n",
    "                                 & (new_data[\"Pclass\"] == new_data.iloc[i][\"Pclass\"])].median()\n",
    "    if np.isnan(AssumedAge):\n",
    "        new_data[\"Age\"][i] = medianAge\n",
    "    else:\n",
    "        new_data[\"Age\"][i] = AssumedAge\n",
    "        \n",
    "# print(AssumedAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4- Observation\n",
    "##### from the correlation graph:\n",
    "- The strongest relationships with survival are: Pclass, Sex, and Fare\n",
    "  - since Pclass 1 is the highest class and Pclass one is the lowest therefore, the lower the Pclass the higher the survival rate, with 33% inverse proportionality\n",
    "  - For Sex Male = 1 and Female = 0 so since the data shows 55% inverse proportionality that means more Females have survived the accident.\n",
    "  - The higher the Fare the more likely the passenger was on a higher class therefor higher rate of survival with Fare being 26% proportional to Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[[\"Pclass\", \"Survived\"]].groupby(\"Pclass\", as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the names to their title\n",
    "\n",
    "Title_Dictionary = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Sir\": \"Royalty\",\n",
    "    \"Lady\": \"Royalty\",\n",
    "    \"the Countess\": \"Royalty\",\n",
    "    \"Dona\": \"Royalty\",\n",
    "    \"Mme\": \"Miss\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\": \"Mrs\",\n",
    "    \"Master\": \"Master\"\n",
    "}\n",
    "\n",
    "new_data.rename(columns={\"Name\": \"Title\"}, inplace=True)\n",
    "for index, Row in new_data.iterrows():\n",
    "    for title in Title_Dictionary:\n",
    "        if title in Row[\"Title\"]:\n",
    "            new_data[\"Title\"][index]= Title_Dictionary.get(title)\n",
    "\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[[\"Title\", \"Survived\"]].groupby(\"Title\", as_index=False).mean().sort_values(by=\"Survived\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the SibSp and Parch columns into one column called FamilySize\n",
    "\n",
    "new_data[\"FamilySize\"] = new_data[\"Parch\"] + new_data[\"SibSp\"] + 1\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[[\"FamilySize\", \"Survived\"]].groupby(\"FamilySize\", as_index=False).mean().sort_values(by=\"Survived\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a feature called isAlone to determine if the passenger is alone or not\n",
    "\n",
    "new_data[\"isAlone\"] = 0\n",
    "new_data.loc[new_data[\"FamilySize\"] == 1, \"isAlone\"] = 1\n",
    "new_data[[\"FamilySize\", \"isAlone\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[[\"isAlone\", \"Survived\"]].groupby(\"isAlone\", as_index=False).mean().sort_values(by=\"Survived\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the correlation between (Title, FamilySize and Survived) and (Title, Fare and Survived)\n",
    "grid = sb.FacetGrid(new_data, col=\"Title\", row=\"Survived\")\n",
    "grid.map(sb.histplot, \"FamilySize\")\n",
    "\n",
    "grid = sb.FacetGrid(new_data, col=\"Title\", row=\"Survived\")\n",
    "grid.map(sb.histplot, \"isAlone\")\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop(columns=[\"FamilySize\", \"SibSp\", \"Parch\"], inplace=True)\n",
    "\n",
    "# new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=[\"Title\"])\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the correlation of all the data after adding title and familysize to the equation\n",
    "dataCorr(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5- Observation\n",
    "##### from the correlation and FacetGrid graph:\n",
    "- Noticed few useless features that dont have much of an effect on the survival rate of the passangers such as:\n",
    "  - Title_Royalty\n",
    "  - Title_Officer\n",
    "  - PassengerId\n",
    "- Some of the key features that are very important:\n",
    "  - Fare\n",
    "  - Sex\n",
    "  - Pclass\n",
    "- Features that have an indirect affect:\n",
    "  - isAlone\n",
    "  - Title_Mrs\n",
    "  - Title_Mr\n",
    "  - Title_Miss\n",
    "  - Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.drop(columns=[\"PassengerId\", \"Embarked_Q\", \"Title_Royalty\", \"Title_Master\"], axis=1)\n",
    "\n",
    "# new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop(columns=[\"Survived\"], axis=1)\n",
    "y = new_data[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(y_test, dt_pred, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
    "sb.heatmap(confusion_matrix, annot = True, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to measure how well the model is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(ypred, classi):\n",
    "    class_report = classification_report(y_test, ypred)\n",
    "    ypred_prob = classi.predict_proba(X_test)[::,1]\n",
    "    fpr, tpr, thresh = roc_curve(y_test, ypred_prob)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    \n",
    "    #create ROC curve\n",
    "    mp.pyplot.plot(fpr,tpr)\n",
    "    mp.pyplot.title(\"ROC Curve\")\n",
    "    mp.pyplot.ylabel('True Positive Rate')\n",
    "    mp.pyplot.xlabel('False Positive Rate')\n",
    "    mp.pyplot.show()\n",
    "    \n",
    "    # Displaying AUC Score\n",
    "    print(f\"The AUC Score is: {auc_score}\")\n",
    "    \n",
    "    # Displaying Classification Score\n",
    "    print(f\"\\nThe Classification Score is:\\n{class_report}\")\n",
    "    \n",
    "    acc = round(accuracy_score(y_test, ypred), 2)\n",
    "    prec = round(precision_score(y_test, ypred), 1)\n",
    "    recall = round(recall_score(y_test, ypred), 2)\n",
    "\n",
    "    print(f\"Accuracy: {acc}\\nPrecision: {prec}\\nRecall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_metric = metrics(dt_pred, dt)\n",
    "dt_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOT data\n",
    "def graphTree(classi):\n",
    "    mp.pyplot.figure(figsize=(10, 10))\n",
    "    plot_tree(classi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTree(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(dt, out_file=None)\n",
    "\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph.render(\"decision_tree_graphivz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2 = DecisionTreeClassifier( max_depth=100, splitter=\"random\", random_state=40)\n",
    "dt2.fit(X_train, y_train)\n",
    "dt_pred2 = dt2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_metric2 = metrics(dt_pred2, dt2)\n",
    "dt_metric2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion=\"entropy\", max_depth=50, n_estimators=100, random_state=40)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metric = metrics(rf_pred, rf)\n",
    "rf_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = {\"Plain Decision Tree\": dt_metric,\n",
    "                   \"Adjusted Decision Tree\": dt_metric2,\n",
    "                   \"Random Forest\": rf_metric}\n",
    "classifier_list = pd.DataFrame(classifier_list)\n",
    "\n",
    "classifier_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f28bfb4324f669a89cc099f355fc57127f6b173621f9e30f28a12375bb1be415"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
